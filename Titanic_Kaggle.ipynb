{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT tutorial on the Titanic dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic machine learning competition on [Kaggle](https://www.kaggle.com/c/titanic) is one of the most popular beginner's competitions on the platform. We will use that competition here to demonstrate the implementation of TPOT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "titanic = pd.read_csv('data/titanic_train.csv')\n",
    "titanic.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a,\n",
    "b,\n",
    "c,\n",
    "a,\n",
    "c,\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding\n",
    "[a,b,c]\n",
    "\n",
    "[1,0,0]\n",
    "\n",
    "[0,1,0]\n",
    "\n",
    "[0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  1           233\n",
       "        0            81\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby('Sex').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Sex     Survived\n",
       "1       female  1            91\n",
       "                0             3\n",
       "        male    0            77\n",
       "                1            45\n",
       "2       female  1            70\n",
       "                0             6\n",
       "        male    0            91\n",
       "                1            17\n",
       "3       female  0            72\n",
       "                1            72\n",
       "        male    0           300\n",
       "                1            47\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(['Pclass','Sex']).Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>female</th>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.631148</td>\n",
       "      <td>0.368852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>female</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.157407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>female</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.864553</td>\n",
       "      <td>0.135447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived            0.0       1.0\n",
       "Pclass Sex                       \n",
       "1      female  0.031915  0.968085\n",
       "       male    0.631148  0.368852\n",
       "2      female  0.078947  0.921053\n",
       "       male    0.842593  0.157407\n",
       "3      female  0.500000  0.500000\n",
       "       male    0.864553  0.135447"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = pd.crosstab([titanic.Pclass, titanic.Sex], titanic.Survived.astype(float))\n",
    "id.div(id.sum(1).astype(float), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and most important step in using TPOT on any data set is to rename the target class/response variable to `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.rename(columns={'Survived': 'class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At present, TPOT requires all the data to be in numerical format. As we can see below, our data set has 5 categorical variables which contain non-numerical values: `Name`, `Sex`, `Ticket`, `Cabin` and `Embarked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "class            int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check the number of levels that each of the five categorical variables have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of levels in category 'Name': \b 891.00 \n",
      "Number of levels in category 'Sex': \b 2.00 \n",
      "Number of levels in category 'Ticket': \b 681.00 \n",
      "Number of levels in category 'Cabin': \b 148.00 \n",
      "Number of levels in category 'Embarked': \b 4.00 \n"
     ]
    }
   ],
   "source": [
    "for cat in ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']:\n",
    "    print(\"Number of levels in category '{0}': \\b {1:2.2f} \".format(cat, titanic[cat].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Sex` and `Embarked` have few levels. Let's find out what they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levels for catgeory 'Sex': ['male' 'female']\n",
      "Levels for catgeory 'Embarked': ['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "for cat in ['Sex', 'Embarked']:\n",
    "    print(\"Levels for catgeory '{0}': {1}\".format(cat, titanic[cat].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then code these levels manually into numerical values. For `nan` i.e. the missing values, we simply replace them with a placeholder value (-999). In fact, we perform this replacement for the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'] = titanic['Sex'].map({'male':0,'female':1})\n",
    "titanic['Embarked'] = titanic['Embarked'].map({'S':0,'C':1,'Q':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "class          False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin          False\n",
       "Embarked       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = titanic.fillna(-999)\n",
    "pd.isnull(titanic).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Name` and `Ticket` have so many levels, we drop them from our analysis for the sake of simplicity. For `Cabin`, we encode the levels as digits using Scikit-learn's [`MultiLabelBinarizer`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) and treat them as new features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "CabinTrans = mlb.fit_transform([{str(val)} for val in titanic['Cabin'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CabinTrans[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unused features from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_new = titanic.drop(['Name','Ticket','Cabin','class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(titanic['Cabin'].unique()) == len(mlb.classes_)), \"Not Equal\" #check correct encoding done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add the encoded features to form the final dataset to be used with TPOT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_new = np.hstack((titanic_new.values,CabinTrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(titanic_new).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind that the final dataset is in the form of a numpy array, we can check the number of features in the final dataset as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_new[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we store the class labels, which we need to predict, in a separate variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_class = titanic['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  3.  ,  0.  , 22.  ,  1.  ,  0.  ,  7.25,  0.  ,  1.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis using TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our analysis, we need to divide our training data into training and validation sets. The validation set is just to give us an idea of the test set error. The model selection and tuning is entirely taken care of by TPOT, so if we want to, we can skip creating this validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 223)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_indices, validation_indices = training_indices, testing_indices = train_test_split(titanic.index, stratify = titanic_class, train_size=0.75, test_size=0.25)\n",
    "training_indices.size, validation_indices.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query -1 \n",
    "\n",
    "Logistic Regression only, tuning hyperparameters using TPOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_worker = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=600, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7919273307647228\n",
      "Generation 2 - Current best internal CV score: 0.7963716089560551\n",
      "Generation 3 - Current best internal CV score: 0.7963716089560551\n",
      "Generation 4 - Current best internal CV score: 0.7963823322817823\n",
      "Generation 5 - Current best internal CV score: 0.8008823883922076\n",
      "\n",
      "Best pipeline: LogisticRegression(LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), max_iter=200, penalty=l2, random_state=42, solver=lbfgs), max_iter=200, penalty=l2, random_state=42, solver=liblinear)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.linear_model.LogisticRegression': {'penalty': ['l1', 'l2'], 'random_state': [42], 'max_iter': [100, 200, 300], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False, early_stop=4,\n",
       "        generations=5, max_eval_time_mins=5, max_time_mins=None,\n",
       "        memory=None, mutation_rate=0.9, n_jobs=12, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=100,\n",
       "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# providing Logit Regression in config param, so that it ll optimize the hyperparameters\n",
    "tpot_config = {\n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty':['l1','l2'],\n",
    "        'random_state':[42], # not sure if this is the right way to keep random state constant\n",
    "        'max_iter':[100,200,300],\n",
    "        'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "}\n",
    "tpot = TPOTClassifier(verbosity=2, generations=5, early_stop=4, n_jobs=num_worker, config_dict=tpot_config)\n",
    "tpot.fit(titanic_new[training_indices], titanic_class[training_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot_logit_5_gen.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tpot_logit_5_gen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=None)\n",
    "\n",
    "# Average CV score on the training set was:0.8008823883922076\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        make_union(\n",
    "            FunctionTransformer(copy),\n",
    "            FunctionTransformer(copy)\n",
    "        )\n",
    "    ),\n",
    "    StackingEstimator(estimator=LogisticRegression(max_iter=200, penalty=\"l2\", random_state=42, solver=\"lbfgs\")),\n",
    "    LogisticRegression(max_iter=200, penalty=\"l2\", random_state=42, solver=\"liblinear\")\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image/stacking.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=200, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Generation 1 - Current best internal CV score: 0.7993009056638278\n",
      "\r\n",
      "Best pipeline: LogisticRegression(LogisticRegression(input_matrix, max_iter=60, penalty=l2, random_state=42, solver=lbfgs), max_iter=40, penalty=l2, random_state=42, solver=liblinear)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.linear_model.LogisticRegression': {'penalty': ['l1', 'l2'], 'random_state': [42], 'max_iter': [40, 50, 60], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}},\n",
       "        crossover_rate=0.1, cv=5, disable_update_check=False,\n",
       "        early_stop=None, generations=1, max_eval_time_mins=5,\n",
       "        max_time_mins=None, memory=None, mutation_rate=0.9, n_jobs=12,\n",
       "        offspring_size=None, periodic_checkpoint_folder=None,\n",
       "        population_size=100, random_state=None, scoring=None,\n",
       "        subsample=1.0, use_dask=False, verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_config = {\n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty':['l1','l2'],\n",
    "        'random_state':[42],\n",
    "        'max_iter':[40,50,60],\n",
    "        'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "}\n",
    "tpot = TPOTClassifier(verbosity=2, generations=1, n_jobs=num_worker, config_dict=tpot_config)\n",
    "tpot.fit(titanic_new[training_indices], titanic_class[training_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot_logit_1_gen.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tpot_logit_1_gen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
    "features = tpot_data.drop('target', axis=1).values\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'].values, random_state=None)\n",
    "\n",
    "# Average CV score on the training set was:0.7993009056638278\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LogisticRegression(max_iter=60, penalty=\"l2\", random_state=42, solver=\"lbfgs\")),\n",
    "    LogisticRegression(max_iter=40, penalty=\"l2\", random_state=42, solver=\"liblinear\")\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I had got confused between POPULATION_SIZE and SUBSAMPLE\n",
    "\n",
    "POPULATION_SIZE - \n",
    "    \n",
    "    Number of individuals to retain in the GP population every generation. \n",
    "    Generally, TPOT will work better when you give it more individuals (and therefore time) to optimize the pipeline. \n",
    "\n",
    "SUBSAMPLE - \n",
    "    \n",
    "    Subsample ratio of the training instance. \n",
    "    Setting it to 0.5 means that TPOT randomly collects half of training samples for pipeline optimization process.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of evaluated Individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6691321171918186},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7919273307647228},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.790412183028051},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.748496697797562},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011852},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7919273307647228},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7215404182097034},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6661358204798896},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6661358204798896},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.776822570522492},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7409110670540364},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7409665124669053},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7889196457146181},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7904347934512899},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7859345710877526},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 0,\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('ROOT',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',\n",
       "   'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(CombineDFs(CombineDFs(input_matrix, input_matrix), input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7829605522928381},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7484188082145662},\n",
       " 'LogisticRegression(CombineDFs(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7349851411281105},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844085337722416},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',\n",
       "   'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)'),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': -inf},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6661358204798896},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829494964608869},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.730451585015607},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7903456817832308},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(CombineDFs(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6691433392768821},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.6691321171918186},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7768669601034095},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829494964608869},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 3,\n",
       "  'internal_cv_score': 0.7889533119698084},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',\n",
       "   'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7948897949683496},\n",
       " 'LogisticRegression(CombineDFs(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829605522928381},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',\n",
       "   'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7963823322817823},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',\n",
       "   'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)'),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844085337722416},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7889196457146181},\n",
       " 'LogisticRegression(LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 3,\n",
       "  'internal_cv_score': 0.6691433392768821},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7378812703400293},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',\n",
       "   'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',\n",
       "   'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6661358204798896},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7859345710877526},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7829605522928381},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7468477163056896},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829494964608869},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7844420337743196},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7874271084011853},\n",
       " 'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs)',\n",
       "   'LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)'),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': -inf},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7814454045561664},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6661358204798896},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(CombineDFs(CombineDFs(input_matrix, input_matrix), input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7919047203414838},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.784453089606271},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7933749797379019},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829382743758234},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7904347934512899},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7993009056638278},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7829382743758234},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7859345710877526},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858},\n",
       " 'LogisticRegression(CombineDFs(input_matrix, CombineDFs(input_matrix, input_matrix)), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 1,\n",
       "  'internal_cv_score': 0.670635876590315},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7814457370623906},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.791882442424469},\n",
       " 'LogisticRegression(LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 3,\n",
       "  'internal_cv_score': 0.6706470986753783},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=lbfgs), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7874267758949612},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=newton-cg)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.7874383304862487},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=sag)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 0,\n",
       "  'crossover_count': 1,\n",
       "  'predecessor': ('LogisticRegression(input_matrix, LogisticRegression__max_iter=40, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',\n",
       "   'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=50, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear)'),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6736433953873074},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=60, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=liblinear), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(CombineDFs(input_matrix, input_matrix), LogisticRegression__max_iter=60, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6721396359888112},\n",
       " 'LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=40, LogisticRegression__penalty=l2, LogisticRegression__random_state=42, LogisticRegression__solver=saga)': {'generation': 'INVALID',\n",
       "  'mutation_count': 1,\n",
       "  'crossover_count': 0,\n",
       "  'predecessor': ('LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga), LogisticRegression__max_iter=50, LogisticRegression__penalty=l1, LogisticRegression__random_state=42, LogisticRegression__solver=saga)',),\n",
       "  'operator_count': 2,\n",
       "  'internal_cv_score': 0.6676395798783858}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.evaluated_individuals_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we proceed to calling the `fit`, `score` and `export` functions on our training dataset. To get a better idea of how these functions work, refer the TPOT documentation [here](http://epistasislab.github.io/tpot/api/).\n",
    "\n",
    "An important TPOT parameter to set is the number of generations. Since our aim is to just illustrate the use of TPOT, we have set it to 5. On a standard laptop with 4GB RAM, it roughly takes 5 minutes per generation to run. For each added generation, it should take 5 mins more. Thus, for the default value of 100, total run time could be roughly around 8 hours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=240, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8112412041712906\n",
      "Generation 2 - Current best internal CV score: 0.8112412041712906\n",
      "Generation 3 - Current best internal CV score: 0.8128456298291334\n",
      "Generation 4 - Current best internal CV score: 0.8128456298291334\n",
      "Generation 5 - Current best internal CV score: 0.8128456298291334\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.45, min_samples_leaf=2, min_samples_split=16, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=4, generations=5,\n",
       "        max_eval_time_mins=0.04, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=40,\n",
       "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(verbosity=2, generations=5, max_eval_time_mins=0.04, population_size=40, early_stop=4)\n",
    "tpot.fit(titanic_new[training_indices], titanic_class[training_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8385650224215246"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(titanic_new[validation_indices], titanic.loc[validation_indices, 'class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the generated code. As we can see, the random forest classifier performed the best on the given dataset out of all the other models that TPOT currently evaluates on. If we ran TPOT for more generations, then the score should improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "from sklearn.ensemble import RandomForestClassifier\r\n",
      "from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "# NOTE: Make sure that the class is labeled 'target' in the data file\r\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\r\n",
      "features = tpot_data.drop('target', axis=1).values\r\n",
      "training_features, testing_features, training_target, testing_target = \\\r\n",
      "            train_test_split(features, tpot_data['target'].values, random_state=None)\r\n",
      "\r\n",
      "# Average CV score on the training set was:0.8128456298291334\r\n",
      "exported_pipeline = RandomForestClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.45, min_samples_leaf=2, min_samples_split=16, n_estimators=100)\r\n",
      "\r\n",
      "exported_pipeline.fit(training_features, training_target)\r\n",
      "results = exported_pipeline.predict(testing_features)\r\n"
     ]
    }
   ],
   "source": [
    "!cat tpot_titanic_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make predictions on the submission data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the submission dataset\n",
    "titanic_sub = pd.read_csv('data/titanic_test.csv')\n",
    "titanic_sub.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important step here is to check for new levels in the categorical variables of the submission dataset that are absent in the training set. We identify them and set them to our placeholder value of '-999', i.e., we treat them as missing values. This ensures training consistency, as otherwise the model does not know what to do with the new levels in  the submission dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nishantgautam/nishant-consult/tpot-prabu/environment/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for var in ['Cabin']: #,'Name','Ticket']:\n",
    "    new = list(set(titanic_sub[var]) - set(titanic[var]))\n",
    "    titanic_sub.ix[titanic_sub[var].isin(new), var] = -999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then carry out the data munging steps as done earlier for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_sub['Sex'] = titanic_sub['Sex'].map({'male':0,'female':1})\n",
    "titanic_sub['Embarked'] = titanic_sub['Embarked'].map({'S':0,'C':1,'Q':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin          False\n",
       "Embarked       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_sub = titanic_sub.fillna(-999)\n",
    "pd.isnull(titanic_sub).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While calling `MultiLabelBinarizer` for the submission data set, we first fit on the training set again to learn the levels and then transform the submission dataset values. This further ensures that only those levels that were present in the training dataset are transformed. If new levels are still found in the submission dataset then it will return an error and we need to go back and check our earlier step of replacing new levels with the placeholder value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "SubCabinTrans = mlb.fit([{str(val)} for val in titanic['Cabin'].values]).transform([{str(val)} for val in titanic_sub['Cabin'].values])\n",
    "titanic_sub = titanic_sub.drop(['Name','Ticket','Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the new submission data set\n",
    "titanic_sub_new = np.hstack((titanic_sub.values,SubCabinTrans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(titanic_sub_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure equal number of features in both the final training and submission dataset\n",
    "assert (titanic_new.shape[1] == titanic_sub_new.shape[1]), \"Not Equal\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "submission = tpot.predict(titanic_sub_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission file\n",
    "final = pd.DataFrame({'PassengerId': titanic_sub['PassengerId'], 'Survived': submission})\n",
    "final.to_csv('data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! We have successfully generated the predictions for the 418 data points in the submission dataset, and we're good to go ahead to submit these predictions on Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "901,0\r\n",
      "902,0\r\n",
      "903,0\r\n",
      "904,1\r\n",
      "905,0\r\n",
      "906,1\r\n",
      "907,1\r\n",
      "908,0\r\n",
      "909,0\r\n",
      "910,1\r\n",
      "911,0\r\n",
      "912,0\r\n",
      "913,0\r\n",
      "914,1\r\n",
      "915,0\r\n",
      "916,1\r\n",
      "917,0\r\n",
      "918,1\r\n",
      "919,0\r\n",
      "920,0\r\n",
      "921,0\r\n",
      "922,0\r\n",
      "923,0\r\n",
      "924,1\r\n",
      "925,0\r\n",
      "926,1\r\n",
      "927,0\r\n",
      "928,0\r\n",
      "929,1\r\n",
      "930,0\r\n",
      "931,0\r\n",
      "932,0\r\n",
      "933,0\r\n",
      "934,0\r\n",
      "935,1\r\n",
      "936,1\r\n",
      "937,0\r\n",
      "938,0\r\n",
      "939,0\r\n",
      "940,1\r\n",
      "941,1\r\n",
      "942,0\r\n",
      "943,0\r\n",
      "944,1\r\n",
      "945,1\r\n",
      "946,0\r\n",
      "947,0\r\n",
      "948,0\r\n",
      "949,0\r\n",
      "950,0\r\n",
      "951,1\r\n",
      "952,0\r\n",
      "953,0\r\n",
      "954,0\r\n",
      "955,1\r\n",
      "956,1\r\n",
      "957,1\r\n",
      "958,1\r\n",
      "959,0\r\n",
      "960,0\r\n",
      "961,1\r\n",
      "962,1\r\n",
      "963,0\r\n",
      "964,1\r\n",
      "965,0\r\n",
      "966,1\r\n",
      "967,0\r\n",
      "968,0\r\n",
      "969,1\r\n",
      "970,0\r\n",
      "971,1\r\n",
      "972,1\r\n",
      "973,0\r\n",
      "974,0\r\n",
      "975,0\r\n",
      "976,0\r\n",
      "977,0\r\n",
      "978,1\r\n",
      "979,1\r\n",
      "980,1\r\n",
      "981,1\r\n",
      "982,1\r\n",
      "983,0\r\n",
      "984,1\r\n",
      "985,0\r\n",
      "986,0\r\n",
      "987,0\r\n",
      "988,1\r\n",
      "989,0\r\n",
      "990,1\r\n",
      "991,0\r\n",
      "992,1\r\n",
      "993,0\r\n",
      "994,0\r\n",
      "995,0\r\n",
      "996,1\r\n",
      "997,0\r\n",
      "998,0\r\n",
      "999,0\r\n",
      "1000,0\r\n",
      "1001,0\r\n",
      "1002,0\r\n",
      "1003,1\r\n",
      "1004,1\r\n",
      "1005,1\r\n",
      "1006,1\r\n",
      "1007,0\r\n",
      "1008,0\r\n",
      "1009,1\r\n",
      "1010,0\r\n",
      "1011,1\r\n",
      "1012,1\r\n",
      "1013,0\r\n",
      "1014,1\r\n",
      "1015,0\r\n",
      "1016,0\r\n",
      "1017,1\r\n",
      "1018,0\r\n",
      "1019,1\r\n",
      "1020,0\r\n",
      "1021,0\r\n",
      "1022,0\r\n",
      "1023,0\r\n",
      "1024,0\r\n",
      "1025,0\r\n",
      "1026,0\r\n",
      "1027,0\r\n",
      "1028,0\r\n",
      "1029,0\r\n",
      "1030,1\r\n",
      "1031,0\r\n",
      "1032,0\r\n",
      "1033,1\r\n",
      "1034,0\r\n",
      "1035,0\r\n",
      "1036,0\r\n",
      "1037,0\r\n",
      "1038,0\r\n",
      "1039,0\r\n",
      "1040,0\r\n",
      "1041,0\r\n",
      "1042,1\r\n",
      "1043,0\r\n",
      "1044,0\r\n",
      "1045,1\r\n",
      "1046,0\r\n",
      "1047,0\r\n",
      "1048,1\r\n",
      "1049,1\r\n",
      "1050,0\r\n",
      "1051,1\r\n",
      "1052,1\r\n",
      "1053,1\r\n",
      "1054,1\r\n",
      "1055,0\r\n",
      "1056,0\r\n",
      "1057,1\r\n",
      "1058,0\r\n",
      "1059,0\r\n",
      "1060,1\r\n",
      "1061,1\r\n",
      "1062,0\r\n",
      "1063,0\r\n",
      "1064,0\r\n",
      "1065,0\r\n",
      "1066,0\r\n",
      "1067,1\r\n",
      "1068,1\r\n",
      "1069,0\r\n",
      "1070,1\r\n",
      "1071,1\r\n",
      "1072,0\r\n",
      "1073,0\r\n",
      "1074,1\r\n",
      "1075,0\r\n",
      "1076,1\r\n",
      "1077,0\r\n",
      "1078,1\r\n",
      "1079,0\r\n",
      "1080,0\r\n",
      "1081,0\r\n",
      "1082,0\r\n",
      "1083,0\r\n",
      "1084,0\r\n",
      "1085,0\r\n",
      "1086,1\r\n",
      "1087,0\r\n",
      "1088,1\r\n",
      "1089,1\r\n",
      "1090,0\r\n",
      "1091,0\r\n",
      "1092,1\r\n",
      "1093,1\r\n",
      "1094,1\r\n",
      "1095,1\r\n",
      "1096,0\r\n",
      "1097,0\r\n",
      "1098,1\r\n",
      "1099,0\r\n",
      "1100,1\r\n",
      "1101,0\r\n",
      "1102,0\r\n",
      "1103,0\r\n",
      "1104,0\r\n",
      "1105,1\r\n",
      "1106,0\r\n",
      "1107,0\r\n",
      "1108,1\r\n",
      "1109,0\r\n",
      "1110,1\r\n",
      "1111,0\r\n",
      "1112,1\r\n",
      "1113,0\r\n",
      "1114,1\r\n",
      "1115,0\r\n",
      "1116,1\r\n",
      "1117,1\r\n",
      "1118,0\r\n",
      "1119,1\r\n",
      "1120,0\r\n",
      "1121,0\r\n",
      "1122,0\r\n",
      "1123,1\r\n",
      "1124,0\r\n",
      "1125,0\r\n",
      "1126,1\r\n",
      "1127,0\r\n",
      "1128,0\r\n",
      "1129,0\r\n",
      "1130,1\r\n",
      "1131,1\r\n",
      "1132,1\r\n",
      "1133,1\r\n",
      "1134,1\r\n",
      "1135,0\r\n",
      "1136,1\r\n",
      "1137,1\r\n",
      "1138,1\r\n",
      "1139,0\r\n",
      "1140,1\r\n",
      "1141,1\r\n",
      "1142,1\r\n",
      "1143,0\r\n",
      "1144,0\r\n",
      "1145,0\r\n",
      "1146,0\r\n",
      "1147,0\r\n",
      "1148,0\r\n",
      "1149,0\r\n",
      "1150,1\r\n",
      "1151,0\r\n",
      "1152,0\r\n",
      "1153,0\r\n",
      "1154,1\r\n",
      "1155,1\r\n",
      "1156,0\r\n",
      "1157,0\r\n",
      "1158,0\r\n",
      "1159,0\r\n",
      "1160,0\r\n",
      "1161,0\r\n",
      "1162,0\r\n",
      "1163,0\r\n",
      "1164,1\r\n",
      "1165,1\r\n",
      "1166,0\r\n",
      "1167,1\r\n",
      "1168,0\r\n",
      "1169,0\r\n",
      "1170,0\r\n",
      "1171,0\r\n",
      "1172,1\r\n",
      "1173,1\r\n",
      "1174,1\r\n",
      "1175,1\r\n",
      "1176,1\r\n",
      "1177,0\r\n",
      "1178,0\r\n",
      "1179,0\r\n",
      "1180,0\r\n",
      "1181,0\r\n",
      "1182,0\r\n",
      "1183,1\r\n",
      "1184,0\r\n",
      "1185,0\r\n",
      "1186,0\r\n",
      "1187,0\r\n",
      "1188,1\r\n",
      "1189,0\r\n",
      "1190,0\r\n",
      "1191,0\r\n",
      "1192,0\r\n",
      "1193,0\r\n",
      "1194,0\r\n",
      "1195,0\r\n",
      "1196,1\r\n",
      "1197,1\r\n",
      "1198,1\r\n",
      "1199,1\r\n",
      "1200,0\r\n",
      "1201,0\r\n",
      "1202,0\r\n",
      "1203,0\r\n",
      "1204,0\r\n",
      "1205,0\r\n",
      "1206,1\r\n",
      "1207,1\r\n",
      "1208,1\r\n",
      "1209,0\r\n",
      "1210,0\r\n",
      "1211,0\r\n",
      "1212,0\r\n",
      "1213,0\r\n",
      "1214,0\r\n",
      "1215,0\r\n",
      "1216,1\r\n",
      "1217,0\r\n",
      "1218,1\r\n",
      "1219,0\r\n",
      "1220,0\r\n",
      "1221,0\r\n",
      "1222,1\r\n",
      "1223,0\r\n",
      "1224,0\r\n",
      "1225,1\r\n",
      "1226,0\r\n",
      "1227,1\r\n",
      "1228,0\r\n",
      "1229,0\r\n",
      "1230,0\r\n",
      "1231,0\r\n",
      "1232,0\r\n",
      "1233,0\r\n",
      "1234,0\r\n",
      "1235,1\r\n",
      "1236,1\r\n",
      "1237,1\r\n",
      "1238,0\r\n",
      "1239,1\r\n",
      "1240,0\r\n",
      "1241,1\r\n",
      "1242,1\r\n",
      "1243,0\r\n",
      "1244,0\r\n",
      "1245,0\r\n",
      "1246,1\r\n",
      "1247,0\r\n",
      "1248,1\r\n",
      "1249,0\r\n",
      "1250,0\r\n",
      "1251,1\r\n",
      "1252,0\r\n",
      "1253,1\r\n",
      "1254,1\r\n",
      "1255,0\r\n",
      "1256,1\r\n",
      "1257,0\r\n",
      "1258,0\r\n",
      "1259,0\r\n",
      "1260,1\r\n",
      "1261,0\r\n",
      "1262,0\r\n",
      "1263,1\r\n",
      "1264,0\r\n",
      "1265,0\r\n",
      "1266,1\r\n",
      "1267,1\r\n",
      "1268,1\r\n",
      "1269,0\r\n",
      "1270,0\r\n",
      "1271,0\r\n",
      "1272,0\r\n",
      "1273,0\r\n",
      "1274,1\r\n",
      "1275,1\r\n",
      "1276,0\r\n",
      "1277,1\r\n",
      "1278,0\r\n",
      "1279,0\r\n",
      "1280,0\r\n",
      "1281,0\r\n",
      "1282,0\r\n",
      "1283,1\r\n",
      "1284,0\r\n",
      "1285,0\r\n",
      "1286,0\r\n",
      "1287,1\r\n",
      "1288,0\r\n",
      "1289,1\r\n",
      "1290,0\r\n",
      "1291,0\r\n",
      "1292,1\r\n",
      "1293,0\r\n",
      "1294,1\r\n",
      "1295,0\r\n",
      "1296,0\r\n",
      "1297,0\r\n",
      "1298,0\r\n",
      "1299,0\r\n",
      "1300,1\r\n",
      "1301,1\r\n",
      "1302,1\r\n",
      "1303,1\r\n",
      "1304,1\r\n",
      "1305,0\r\n",
      "1306,1\r\n",
      "1307,0\r\n",
      "1308,0\r\n",
      "1309,1\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
